{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwjaRki_Z_z8"
      },
      "source": [
        "**DEEP LEARNING**\n",
        "\n",
        "RBM-Tensorflow\n",
        "\n",
        "GABRIEL JOSHUA . R\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "(train_data, _), (test_data, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_data = train_data / np.float32(255)\n",
        "train_data = np.reshape(train_data, (train_data.shape[0], 784))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "test_data = test_data / np.float32(255)\n",
        "test_data = np.reshape(test_data, (test_data.shape[0], 784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Restricted Boltzmann Machine (RBM) class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class RBM(object):\n",
        "    def __init__(self, input_size, output_size, lr=1.0, batchsize=100):\n",
        "        \"\"\"\n",
        "        Initialize RBM with hyperparameters.\n",
        "        \"\"\"\n",
        "        self._input_size = input_size  # Size of visible layer\n",
        "        self._output_size = output_size  # Size of hidden layer\n",
        "        self.learning_rate = lr  # The step used in gradient descent\n",
        "        self.batchsize = batchsize  # The size of the training data used per sub-iteration\n",
        "\n",
        "        # Initialize weights and biases as matrices full of zeroes\n",
        "        self.w = tf.zeros([input_size, output_size], np.float32)  # Weight matrix\n",
        "        self.hb = tf.zeros([output_size], np.float32)  # Hidden biases\n",
        "        self.vb = tf.zeros([input_size], np.float32)  # Visible biases\n",
        "\n",
        "    # Forward Pass: Probability of hidden units given visible units\n",
        "    def prob_h_given_v(self, visible, w, hb):\n",
        "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
        "\n",
        "    # Backward Pass: Probability of visible units given hidden units\n",
        "    def prob_v_given_h(self, hidden, w, vb):\n",
        "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
        "\n",
        "    # Generate the sample probability for binary units\n",
        "    def sample_prob(self, probs):\n",
        "        return tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs))))\n",
        "\n",
        "    # Training method for the model\n",
        "    def train(self, X, epochs=10):\n",
        "        loss = []\n",
        "        for epoch in range(epochs):\n",
        "            # For each step/batch\n",
        "            for start, end in zip(range(0, len(X), self.batchsize), range(self.batchsize, len(X), self.batchsize)):\n",
        "                batch = X[start:end]\n",
        "\n",
        "                # Gibbs sampling: Contrastive Divergence\n",
        "                h0 = self.sample_prob(self.prob_h_given_v(batch, self.w, self.hb))  # p(h|input)\n",
        "                v1 = self.sample_prob(self.prob_v_given_h(h0, self.w, self.vb))  # p(v|h)\n",
        "                h1 = self.prob_h_given_v(v1, self.w, self.hb)  # p(h|v)\n",
        "\n",
        "                # Create the Gradients\n",
        "                positive_grad = tf.matmul(tf.transpose(batch), h0)\n",
        "                negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
        "\n",
        "                # Update weights and biases using gradient descent\n",
        "                self.w = self.w + self.learning_rate * (positive_grad - negative_grad) / tf.dtypes.cast(tf.shape(batch)[0], tf.float32)\n",
        "                self.vb = self.vb + self.learning_rate * tf.reduce_mean(batch - v1, 0)\n",
        "                self.hb = self.hb + self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
        "\n",
        "            # Calculate reconstruction error and store it\n",
        "            err = tf.reduce_mean(tf.square(batch - v1))\n",
        "            print('Epoch: %d' % epoch, 'reconstruction error: %f' % err)\n",
        "            loss.append(err)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Generate output from the RBM\n",
        "    def rbm_output(self, X):\n",
        "        out = tf.nn.sigmoid(tf.matmul(X, self.w) + self.hb)\n",
        "        return out\n",
        "\n",
        "    # Reconstruct input data using the RBM\n",
        "    def rbm_reconstruct(self, X):\n",
        "        h = tf.nn.sigmoid(tf.matmul(X, self.w) + self.hb)\n",
        "        reconstruct = tf.nn.sigmoid(tf.matmul(h, tf.transpose(self.w)) + self.vb)\n",
        "        return reconstruct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instantiate the RBM class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "input_size = train_data.shape[1]\n",
        "rbm = RBM(input_size, 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the RBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "err = rbm.train(train_data, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the reconstruction error over epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(err)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('cost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reconstruct test data using the trained RBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "out = rbm.rbm_reconstruct(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot original and reconstructed images side by side\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "row, col = 2, 8\n",
        "idx = np.random.randint(0, 100, row * col // 2)\n",
        "f, axarr = plt.subplots(row, col, sharex=True, sharey=True, figsize=(20, 4))\n",
        "for fig, row in zip([test_data, out], axarr):\n",
        "    for i, ax in zip(idx, row):\n",
        "        ax.imshow(tf.reshape(fig[i], [28, 28]), cmap='Greys_r')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
